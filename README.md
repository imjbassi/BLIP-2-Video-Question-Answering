# BLIP-2-Video-Question-Answering
This project implements a pipeline for multiple-choice Video Question Answering (VQA) using BLIP-2, applied to the Perception Test Challenge dataset hosted by Google DeepMind. It leverages frame-based prompting to infer answers from video clips using language-vision models.
